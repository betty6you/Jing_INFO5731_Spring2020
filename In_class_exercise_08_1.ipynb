{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/betty6you/Jing_INFO5731_Spring2020/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_-W0dXquLBA"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifJz36ytuLBC"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVUrQBPtuLBD"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "kgmo6-ailuY1",
        "outputId": "685789d8-6b3c-4dd3-cb49-81cdba39c5cb"
      },
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!polyglot download sentiment2.en\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(r\"https://raw.githubusercontent.com/betty6you/Jing_INFO5731_Spring2020/main/AmazonReviewupdated_sentiment_renew.csv\")\n",
        "\n",
        "\n",
        "from polyglot.text import Text # I tried the method offer online, but still it doesn't work, but the code in total should be correct\n",
        "sentimentWords = []\n",
        "for row_content in data['Review']:\n",
        "  line_text = Text(row_content)\n",
        "  for word in line_text.words:\n",
        "    if word.polarity != 0:\n",
        "      sentimentWords.append(word)\n",
        "sentimentWords"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: polyglot in /usr/local/lib/python3.7/dist-packages (16.7.4)\n",
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.7/dist-packages (2.6)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.7/dist-packages (0.41)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (2.0.6)\n",
            "[polyglot_data] Downloading package sentiment2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data]   Package sentiment2.en is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b1e3d72ad527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msentimentWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstmt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/polyglot/text.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextFiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/polyglot/detect/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Detector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Language'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/polyglot/detect/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycld2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcld2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Locale' from 'icu' (/usr/local/lib/python3.7/dist-packages/icu/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xsPAPGPuLBE"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "0JnU6sAZof0t",
        "outputId": "1ac43c0c-6bb2-49af-c2fe-37b26cfa87a6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# TextBlob method\n",
        "from textblob import TextBlob, Word, Blobber\n",
        "\n",
        "data = pd.read_csv(r\"https://raw.githubusercontent.com/betty6you/Jing_INFO5731_Spring2020/main/AmazonReviewupdated_sentiment_renew.csv\")\n",
        "print(data.shape)\n",
        "data.head()\n",
        "data['Polarity']=data['Review'].apply(lambda x: TextBlob(x).sentiment[0]) # if polarity is near 1, it's positive, if is near -1, it's negative\n",
        "data['comp_senti'] = data['Polarity'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
        "data"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(111, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>comp_senti</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>product arrived damaged and not working seller...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>came in evening around 11pm so in thankful usp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.240210</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this laptop wa ok for the price lack of usbc i...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is not the touch screen a advertised noth...</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.425000</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>laptop randomly shut itself off and would not ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.010606</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>meet all my expectationsso far</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>wasnt planning on buying a labtop but had to i...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>server it purpose for a field superintentent</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>best laptop</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>i like that it is very nice and the touchscree...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review  ... comp_senti\n",
              "0    product arrived damaged and not working seller...  ...        pos\n",
              "1    came in evening around 11pm so in thankful usp...  ...        pos\n",
              "2    this laptop wa ok for the price lack of usbc i...  ...        pos\n",
              "3    this is not the touch screen a advertised noth...  ...        neg\n",
              "4    laptop randomly shut itself off and would not ...  ...        pos\n",
              "..                                                 ...  ...        ...\n",
              "106                     meet all my expectationsso far  ...        pos\n",
              "107  wasnt planning on buying a labtop but had to i...  ...        pos\n",
              "108       server it purpose for a field superintentent  ...        pos\n",
              "109                                        best laptop  ...        pos\n",
              "110  i like that it is very nice and the touchscree...  ...        pos\n",
              "\n",
              "[111 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "owxLvbNdr2jP",
        "outputId": "f1e415ae-0678-4fab-8699-bc31f9830070"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(r\"https://raw.githubusercontent.com/betty6you/Jing_INFO5731_Spring2020/main/AmazonReviewupdated_sentiment_renew.csv\")\n",
        "data.head()\n",
        "data['scores'] = data['Review'].apply(lambda review: sid.polarity_scores(review))\n",
        "data.head()\n",
        "data['compound']  = data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "data.head()\n",
        "\n",
        "data['comp_score'] = data['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound</th>\n",
              "      <th>comp_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>product arrived damaged and not working seller...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{'neg': 0.289, 'neu': 0.652, 'pos': 0.059, 'co...</td>\n",
              "      <td>-0.8132</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>came in evening around 11pm so in thankful usp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{'neg': 0.046, 'neu': 0.72, 'pos': 0.234, 'com...</td>\n",
              "      <td>0.9676</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this laptop wa ok for the price lack of usbc i...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{'neg': 0.215, 'neu': 0.698, 'pos': 0.087, 'co...</td>\n",
              "      <td>-0.7591</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is not the touch screen a advertised noth...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{'neg': 0.17, 'neu': 0.799, 'pos': 0.032, 'com...</td>\n",
              "      <td>-0.8147</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>laptop randomly shut itself off and would not ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{'neg': 0.038, 'neu': 0.85, 'pos': 0.112, 'com...</td>\n",
              "      <td>0.4881</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  ... comp_score\n",
              "0  product arrived damaged and not working seller...  ...        neg\n",
              "1  came in evening around 11pm so in thankful usp...  ...        pos\n",
              "2  this laptop wa ok for the price lack of usbc i...  ...        neg\n",
              "3  this is not the touch screen a advertised noth...  ...        neg\n",
              "4  laptop randomly shut itself off and would not ...  ...        pos\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "BX_n_BYx9YDV",
        "outputId": "834f69a3-4be0-40d3-f016-e007e5c02223"
      },
      "source": [
        "import pandas as pd\n",
        "# train Data\n",
        "trainData = pd.read_csv(\"https://raw.githubusercontent.com/betty6you/Jing_INFO5731_Spring2020/main/sentiment_Train_data.csv\")\n",
        "# test Data\n",
        "testData = pd.read_csv(\"https://raw.githubusercontent.com/betty6you/Jing_INFO5731_Spring2020/main/sentiment_Test_data.csv\")\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "train_vectors = vectorizer.fit_transform(trainData['Review'])\n",
        "test_vectors = vectorizer.transform(testData['Review'])\n",
        "\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "# Perform classification with SVM, kernel=linear\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, trainData['sentiment'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "report = classification_report(testData['sentiment'], prediction_linear, output_dict=True)\n",
        "print('positive: ', report['positive'])\n",
        "print('negative: ', report['negative'])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 0.002400s; Prediction time: 0.000681s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-1a08e6322c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time: %fs; Prediction time: %fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_linear_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_linear_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment'"
          ]
        }
      ]
    }
  ]
}