{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/betty6you/Jing_INFO5731_Spring2020/blob/main/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1gAJLhImApq"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCjYdfTmApr"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ci0vloXmApt"
      },
      "source": [
        "# Write your code here\n",
        "# 10 fold cross validation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import svm"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOYi85YYYgDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "64a4146f-da46-47bd-a2f2-896edb79bcac"
      },
      "source": [
        "# reading training data\n",
        "\n",
        "data= open('stsa-train1.txt').read()\n",
        "labels,texts=[],[]\n",
        "for line in data.split(\"\\n\"):\n",
        "  content=line.split( )  \n",
        "  labels.append(content[0])\n",
        "  texts.append(\" \".join(content[1:]))\n",
        "\n",
        "# create a dataframe using texts and labels\n",
        "trainDF=pd.DataFrame()\n",
        "trainDF['text']=texts\n",
        "trainDF['label']=labels\n",
        "trainDF"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text label\n",
              "0     a stirring , funny and finally transporting re...     1\n",
              "1     apparently reassembled from the cutting-room f...     0\n",
              "2     they presume their audience wo n't sit still f...     0\n",
              "3     this is a visually stunning rumination on love...     1\n",
              "4     jonathan parker 's bartleby should have been t...     1\n",
              "...                                                 ...   ...\n",
              "6915  painful , horrifying and oppressively tragic ,...     1\n",
              "6916  take care is nicely performed by a quintet of ...     0\n",
              "6917  the script covers huge , heavy topics in a bla...     0\n",
              "6918  a seriously bad film with seriously warped log...     0\n",
              "6919  a deliciously nonsensical comedy about a city ...     1\n",
              "\n",
              "[6920 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "VSCh8S5vLYup",
        "outputId": "a17cc71c-48d4-4234-b333-67cc44951915"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "nltk.download('wordnet')\n",
        "st = PorterStemmer()\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "# data clean\n",
        "trainDF['Lowercase'] = trainDF['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "trainDF['Removepunct'] = trainDF['Lowercase'].str.replace('[^\\w\\s]','')\n",
        "trainDF['Removespecialchar'] = trainDF['Removepunct'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "trainDF['Removestopwords'] = trainDF['Removespecialchar'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "trainDF['Tokenization'] = trainDF['Removestopwords'].apply(lambda x: TextBlob(x).words)\n",
        "trainDF['Lemmatization'] = trainDF['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "trainDF"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>Lowercase</th>\n",
              "      <th>Removepunct</th>\n",
              "      <th>Removespecialchar</th>\n",
              "      <th>Removestopwords</th>\n",
              "      <th>Tokenization</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "      <td>[stirring, funny, finally, transporting, reima...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "      <td>[apparently, reassembled, cuttingroom, floor, ...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "      <td>[presume, audience, wo, nt, sit, still, sociol...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "      <td>[visually, stunning, rumination, love, memory,...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "      <td>[jonathan, parker, bartleby, beallendall, mode...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>painful  horrifying and oppressively tragic  t...</td>\n",
              "      <td>painful  horrifying and oppressively tragic  t...</td>\n",
              "      <td>painful horrifying oppressively tragic film mi...</td>\n",
              "      <td>[painful, horrifying, oppressively, tragic, fi...</td>\n",
              "      <td>painful horrifying oppressively tragic film mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care nicely performed quintet actresses n...</td>\n",
              "      <td>[take, care, nicely, performed, quintet, actre...</td>\n",
              "      <td>take care nicely performed quintet actress non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>the script covers huge  heavy topics in a blan...</td>\n",
              "      <td>the script covers huge  heavy topics in a blan...</td>\n",
              "      <td>script covers huge heavy topics bland surfacey...</td>\n",
              "      <td>[script, covers, huge, heavy, topics, bland, s...</td>\n",
              "      <td>script cover huge heavy topic bland surfacey w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>seriously bad film seriously warped logic writ...</td>\n",
              "      <td>[seriously, bad, film, seriously, warped, logi...</td>\n",
              "      <td>seriously bad film seriously warped logic writ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>deliciously nonsensical comedy city coming apa...</td>\n",
              "      <td>[deliciously, nonsensical, comedy, city, comin...</td>\n",
              "      <td>deliciously nonsensical comedy city coming apa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...                                      Lemmatization\n",
              "0     a stirring , funny and finally transporting re...  ...  stirring funny finally transporting reimaginin...\n",
              "1     apparently reassembled from the cutting-room f...  ...  apparently reassembled cuttingroom floor given...\n",
              "2     they presume their audience wo n't sit still f...  ...  presume audience wo nt sit still sociology les...\n",
              "3     this is a visually stunning rumination on love...  ...  visually stunning rumination love memory histo...\n",
              "4     jonathan parker 's bartleby should have been t...  ...  jonathan parker bartleby beallendall modernoff...\n",
              "...                                                 ...  ...                                                ...\n",
              "6915  painful , horrifying and oppressively tragic ,...  ...  painful horrifying oppressively tragic film mi...\n",
              "6916  take care is nicely performed by a quintet of ...  ...  take care nicely performed quintet actress non...\n",
              "6917  the script covers huge , heavy topics in a bla...  ...  script cover huge heavy topic bland surfacey w...\n",
              "6918  a seriously bad film with seriously warped log...  ...  seriously bad film seriously warped logic writ...\n",
              "6919  a deliciously nonsensical comedy about a city ...  ...  deliciously nonsensical comedy city coming apa...\n",
              "\n",
              "[6920 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "NzHhY26ZO8zI",
        "outputId": "a071281d-cf76-4d95-e4bd-58c610095710"
      },
      "source": [
        "# reading test data\n",
        "testdata= open('stsa-test.txt').read()\n",
        "testlabels,testtexts=[],[]\n",
        "for line in testdata.split(\"\\n\"):\n",
        "  content=line.split( )  \n",
        "  testlabels.append(content[0])\n",
        "  testtexts.append(\" \".join(content[1:]))\n",
        "\n",
        "# create a dataframe using texts and labels\\\n",
        "testDF=pd.DataFrame()\n",
        "testDF['text']=testtexts\n",
        "testDF['label']=testlabels\n",
        "testDF"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text label\n",
              "0        no movement , no yuks , not much of anything .     0\n",
              "1     a gob of drivel so sickly sweet , even the eag...     0\n",
              "2     gangs of new york is an unapologetic mess , wh...     0\n",
              "3     we never really feel involved with the story ,...     0\n",
              "4               this is one of polanski 's best films .     1\n",
              "...                                                 ...   ...\n",
              "1816  an often-deadly boring , strange reading of a ...     0\n",
              "1817  the problem with concept films is that if the ...     0\n",
              "1818  safe conduct , however ambitious and well-inte...     0\n",
              "1819  a film made with as little wit , interest , an...     0\n",
              "1820  but here 's the real damn : it is n't funny , ...     0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "mZghgqNqQ-17",
        "outputId": "15c2e1af-4419-4189-9e4e-3b5106845943"
      },
      "source": [
        "# test data cleaning\n",
        "testDF['Lowercase'] = testDF['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "testDF['Removepunct'] = testDF['Lowercase'].str.replace('[^\\w\\s]','')\n",
        "testDF['Removespecialchar'] = testDF['Removepunct'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "testDF['Removestopwords'] = testDF['Removespecialchar'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "testDF['Tokenization'] = testDF['Removestopwords'].apply(lambda x: TextBlob(x).words)\n",
        "testDF['Lemmatization'] = testDF['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "testDF"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>Lowercase</th>\n",
              "      <th>Removepunct</th>\n",
              "      <th>Removespecialchar</th>\n",
              "      <th>Removestopwords</th>\n",
              "      <th>Tokenization</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "      <td>[movement, yuks, much, anything]</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "      <td>[gob, drivel, sickly, sweet, even, eager, cons...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumer mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "      <td>[gangs, new, york, unapologetic, mess, whose, ...</td>\n",
              "      <td>gang new york unapologetic mess whose saving g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "      <td>[never, really, feel, involved, story, ideas, ...</td>\n",
              "      <td>never really feel involved story idea remain a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>one polanski best films</td>\n",
              "      <td>[one, polanski, best, films]</td>\n",
              "      <td>one polanski best film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>an oftendeadly boring  strange reading of a cl...</td>\n",
              "      <td>an oftendeadly boring  strange reading of a cl...</td>\n",
              "      <td>oftendeadly boring strange reading classic who...</td>\n",
              "      <td>[oftendeadly, boring, strange, reading, classi...</td>\n",
              "      <td>oftendeadly boring strange reading classic who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>problem concept films concept poor one saving ...</td>\n",
              "      <td>[problem, concept, films, concept, poor, one, ...</td>\n",
              "      <td>problem concept film concept poor one saving m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>safe conduct  however ambitious and wellintent...</td>\n",
              "      <td>safe conduct  however ambitious and wellintent...</td>\n",
              "      <td>safe conduct however ambitious wellintentioned...</td>\n",
              "      <td>[safe, conduct, however, ambitious, wellintent...</td>\n",
              "      <td>safe conduct however ambitious wellintentioned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>a film made with as little wit  interest  and ...</td>\n",
              "      <td>a film made with as little wit  interest  and ...</td>\n",
              "      <td>film made little wit interest professionalism ...</td>\n",
              "      <td>[film, made, little, wit, interest, profession...</td>\n",
              "      <td>film made little wit interest professionalism ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>but here s the real damn  it is nt funny  either</td>\n",
              "      <td>but here s the real damn  it is nt funny  either</td>\n",
              "      <td>real damn nt funny either</td>\n",
              "      <td>[real, damn, nt, funny, either]</td>\n",
              "      <td>real damn nt funny either</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...                                      Lemmatization\n",
              "0        no movement , no yuks , not much of anything .  ...                        movement yuks much anything\n",
              "1     a gob of drivel so sickly sweet , even the eag...  ...  gob drivel sickly sweet even eager consumer mo...\n",
              "2     gangs of new york is an unapologetic mess , wh...  ...  gang new york unapologetic mess whose saving g...\n",
              "3     we never really feel involved with the story ,...  ...  never really feel involved story idea remain a...\n",
              "4               this is one of polanski 's best films .  ...                             one polanski best film\n",
              "...                                                 ...  ...                                                ...\n",
              "1816  an often-deadly boring , strange reading of a ...  ...  oftendeadly boring strange reading classic who...\n",
              "1817  the problem with concept films is that if the ...  ...  problem concept film concept poor one saving m...\n",
              "1818  safe conduct , however ambitious and well-inte...  ...  safe conduct however ambitious wellintentioned...\n",
              "1819  a film made with as little wit , interest , an...  ...  film made little wit interest professionalism ...\n",
              "1820  but here 's the real damn : it is n't funny , ...  ...                          real damn nt funny either\n",
              "\n",
              "[1821 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2dmKD7rVz1G"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
        "tfidf_vect.fit(trainDF['Lemmatization'])\n",
        "x_tfidf =  tfidf_vect.transform(trainDF['Lemmatization'])\n",
        "vect_test = TfidfVectorizer(analyzer='word', vocabulary = tfidf_vect.vocabulary_)\n",
        "vect_test.fit(testDF['Lemmatization'])\n",
        "xtest = vect_test.transform(testDF['Lemmatization'])\n",
        "test_y = testDF['label']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bAtWI3hXJQr",
        "outputId": "50b94557-bfd2-4461-fb1c-2cf54a4ac0b3"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
        "from sklearn import metrics\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(x_tfidf,trainDF['label'].values,test_size=0.2)\n",
        "print(train_y)\n",
        "from sklearn import metrics\n",
        "def get_metrics(predictions, test_data_y):\n",
        "  accuracy = metrics.accuracy_score(predictions, test_data_y)\n",
        "  precision = metrics.precision_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  recall = metrics.recall_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  f1 = metrics.f1_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  return accuracy, precision, recall, f1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "def cross_validation_score(modelName, x, y):\n",
        "  scoring = 'accuracy'\n",
        "  kfold = KFold(10, random_state = 7,shuffle=True)\n",
        "  cross_val = cross_val_score(modelName, x, y, cv=kfold).mean()\n",
        "  return cross_val"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0' '0' '0' ... '1' '1' '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg41axeXXWXp",
        "outputId": "d1f51d2b-1a19-44d2-b370-02c1903ffb35"
      },
      "source": [
        "#multinomialNB model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "naive_bayes_model = naive_bayes.MultinomialNB()\n",
        "naive_bayes_model.fit(train_x, train_y)\n",
        "naive_bayes_predictions_validation_data = naive_bayes_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(naive_bayes_predictions_validation_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# cross validation score\n",
        "nb_scores_mean = cross_validation_score(naive_bayes_model, valid_x, valid_y)\n",
        "print('Navie Bayes Cross Validation Score is {0}'.format(nb_scores_mean))\n",
        "#model performance evaluation\n",
        "naive_bayes_predictions_test_data = naive_bayes_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(naive_bayes_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7832369942196532\n",
            "Precision is 0.7832369942196532\n",
            "Recall is 0.7832369942196532\n",
            "F1 is 0.7832369942196532\n",
            "Navie Bayes Cross Validation Score is 0.735564591804817\n",
            "Accuracy is 0.7880285557386052\n",
            "Precision is 0.7880285557386052\n",
            "Recall is 0.7880285557386052\n",
            "F1 is 0.7880285557386053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qOSkaPAo2xY",
        "outputId": "1778ef78-9a20-45de-d75b-8612e8241f27"
      },
      "source": [
        "# SVM model\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(train_x, train_y)\n",
        "svm_predictions_validation_data = svm_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(svm_predictions_validation_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# Cross validation score\n",
        "svm_scores_mean = cross_validation_score(svm_model, valid_x, valid_y)\n",
        "print('SVM Cross Validation Score is {0}'.format(svm_scores_mean))\n",
        "svm_predictions_test_data = svm_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(svm_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7796242774566474\n",
            "Precision is 0.7796242774566474\n",
            "Recall is 0.7796242774566474\n",
            "F1 is 0.7796242774566473\n",
            "SVM Cross Validation Score is 0.7081169846731311\n",
            "Accuracy is 0.7951674903898956\n",
            "Precision is 0.7951674903898956\n",
            "Recall is 0.7951674903898956\n",
            "F1 is 0.7951674903898956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vfxADd_p_oy",
        "outputId": "cb8fd0f5-2884-434f-e6ff-3626a0e8ef6f"
      },
      "source": [
        "# KNN model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 15)\n",
        "knn_model.fit(train_x, train_y)\n",
        "knn_predictions_valid_data = knn_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(knn_predictions_valid_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# Cross validation score\n",
        "knn_scores_mean = cross_validation_score(knn_model, valid_x, valid_y)\n",
        "print('KNN Cross Validation Score is {0}'.format(knn_scores_mean))\n",
        "# KNN performance evaluation\n",
        "knn_predictions_test_data = knn_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(knn_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7239884393063584\n",
            "Precision is 0.7239884393063584\n",
            "Recall is 0.7239884393063584\n",
            "F1 is 0.7239884393063584\n",
            "KNN Cross Validation Score is 0.6856949223230112\n",
            "Accuracy is 0.729818780889621\n",
            "Precision is 0.729818780889621\n",
            "Recall is 0.729818780889621\n",
            "F1 is 0.729818780889621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8vhu7XiqQkI",
        "outputId": "0e1adcf6-dd11-4325-de91-e1397b3ae403"
      },
      "source": [
        "#Decision tree model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(train_x, train_y)\n",
        "dt_predictions_valid_data = dt_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(dt_predictions_valid_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# Cross validation score\n",
        "dt_scores_mean = cross_validation_score(dt_model, valid_x, valid_y)\n",
        "print('Decision Tree Cross Validation Score is {0}'.format(dt_scores_mean))\n",
        "# Decision tree performance evaluation\n",
        "dt_predictions_test_data = dt_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(dt_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.6763005780346821\n",
            "Precision is 0.6763005780346821\n",
            "Recall is 0.6763005780346821\n",
            "F1 is 0.6763005780346821\n",
            "Decision Tree Cross Validation Score is 0.5852830778855177\n",
            "Accuracy is 0.6540362438220758\n",
            "Precision is 0.6540362438220758\n",
            "Recall is 0.6540362438220758\n",
            "F1 is 0.6540362438220758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWhZdHFQqoY5",
        "outputId": "143d2217-7d12-4e71-9f3c-d89bdc8d413f"
      },
      "source": [
        "# Random forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(train_x, train_y)\n",
        "rf_predictions_valid_data = rf_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(rf_predictions_valid_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# Cross validation score\n",
        "rf_scores_mean = cross_validation_score(rf_model, valid_x, valid_y)\n",
        "print('Random Forest Cross Validation Score is {0}'.format(rf_scores_mean))\n",
        "# model performance evaluation\n",
        "rf_predictions_test_data = rf_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(rf_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7333815028901735\n",
            "Precision is 0.7333815028901735\n",
            "Recall is 0.7333815028901735\n",
            "F1 is 0.7333815028901733\n",
            "Random Forest Cross Validation Score is 0.651089563132103\n",
            "Accuracy is 0.7413509060955519\n",
            "Precision is 0.7413509060955519\n",
            "Recall is 0.7413509060955519\n",
            "F1 is 0.7413509060955519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJDeD0VdrDT8",
        "outputId": "b5dd5e58-3db7-468e-ef56-58a13622922b"
      },
      "source": [
        "# XG Boost validation Matrix\n",
        "from xgboost import XGBClassifier\n",
        "xg_model = XGBClassifier()\n",
        "xg_model.fit(train_x, train_y)\n",
        "xg_predictions_valid_data = xg_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = get_metrics(xg_predictions_valid_data, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "# Cross validation score\n",
        "xg_scores_mean = cross_validation_score(XGBClassifier(), valid_x, valid_y)\n",
        "print('XG Boost Cross Validation Score is {0}'.format(xg_scores_mean))\n",
        "# model evaluation\n",
        "xg_predictions_test_data = xg_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = get_metrics(xg_predictions_test_data, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.6278901734104047\n",
            "Precision is 0.6278901734104047\n",
            "Recall is 0.6278901734104047\n",
            "F1 is 0.6278901734104047\n",
            "XG Boost Cross Validation Score is 0.6011156292357418\n",
            "Accuracy is 0.6331685886875343\n",
            "Precision is 0.6331685886875343\n",
            "Recall is 0.6331685886875343\n",
            "F1 is 0.6331685886875343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtJVQuCprZfp"
      },
      "source": [
        ""
      ]
    }
  ]
}